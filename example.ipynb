{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Example"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this example, we will find public lidar data on an online server, download data, clean it, canopy height statistics, and write files locally."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Find point cloud data\n",
    "First we need to get some data to work with. I will show one method to pull data from an online server. First, we must define an area of interest using a bounding box `[xmin, ymin, xmax, ymax]`. \n",
    "\n",
    "In the first cell, I demonstrate how you can extract a bounding box from an interactive map using ipyleaflet (`conda install ipyleaflet`). Alternatively, you can skip this step and input a bounding box manually."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T19:32:51.744505Z",
     "start_time": "2025-07-17T19:32:51.720985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ipyleaflet\n",
    "import numpy as np\n",
    "\n",
    "basemap = ipyleaflet.TileLayer(url='https://services.arcgisonline.com/arcgis/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}')\n",
    "m = ipyleaflet.Map(center=[39, -100], zoom=5, scroll_wheel_zoom=True, basemap=basemap)\n",
    "m.add(ipyleaflet.WMSLayer(url='https://index.nationalmap.gov:443/arcgis/services/3DEPElevationIndex/MapServer/WmsServer?',\n",
    "                          layers='23',opacity=.5,name='USGS 3DEP overlay'))\n",
    "m.add(ipyleaflet.LayersControl())\n",
    "bbox = None\n",
    "def handle_draw(target, action, geo_json):\n",
    "    global bbox\n",
    "    coords = geo_json['geometry']['coordinates'][0]\n",
    "    bbox = [coords[0][0], coords[0][1], coords[2][0], coords[2][1]]\n",
    "draw_control = ipyleaflet.DrawControl(rectangle={'shapeOptions': {'color': '#0000FF'}},\n",
    "    polyline={}, polygon={}, circle={}, circlemarker={}, marker={}\n",
    ")\n",
    "draw_control.on_draw(handle_draw)\n",
    "m.add_control(draw_control)\n",
    "m"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map(center=[39, -100], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_out_tâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "377f03bd9e284ab495f129d810637ff9"
      }
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T19:32:51.855036Z",
     "start_time": "2025-07-17T19:32:51.842030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print bounding box selected in interactive map\n",
    "bbox\n",
    "\n",
    "# If you want manually input a bounding box, uncomment the line below and edit the values\n",
    "bbox = [-111.676326, 35.316211, -111.671391, 35.320098]"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we can search the USGS 3DEP catalog to find publicly available point clouds that overlap our area of interest using `pdal_piper.USGS_3dep_Finder`. USGS 3DEP is stored in Entwine Point Tile (.ept) format which means we can efficiently download small segments of the point cloud using a url."
  },
  {
   "cell_type": "code",
   "source": [
    "import pdal_piper\n",
    "finder = pdal_piper.USGS_3dep_Finder()\n",
    "finder.search_3dep(bbox,'EPSG:4326')\n",
    "finder.search_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-17T19:32:53.710468Z",
     "start_time": "2025-07-17T19:32:51.872553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                          name    id  pct_coverage  \\\n",
       "120                        AZ_Coconino_B1_2019   120         100.0   \n",
       "1253  USGS_LPC_AZ_VerdeKaibab_B2_2018_LAS_2019  1253         100.0   \n",
       "\n",
       "      pts_per_m2        count  total_area_ha  \\\n",
       "120    15.372670  55223690056  359232.920560   \n",
       "1253    5.324541  35728383864  671013.439139   \n",
       "\n",
       "                                                    url  \\\n",
       "120   https://s3-us-west-2.amazonaws.com/usgs-lidar-...   \n",
       "1253  https://s3-us-west-2.amazonaws.com/usgs-lidar-...   \n",
       "\n",
       "                                               geometry  \n",
       "120   POLYGON ((-111.67633 35.3201, -111.67139 35.32...  \n",
       "1253  POLYGON ((-111.67633 35.3201, -111.67139 35.32...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>pct_coverage</th>\n",
       "      <th>pts_per_m2</th>\n",
       "      <th>count</th>\n",
       "      <th>total_area_ha</th>\n",
       "      <th>url</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>AZ_Coconino_B1_2019</td>\n",
       "      <td>120</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15.372670</td>\n",
       "      <td>55223690056</td>\n",
       "      <td>359232.920560</td>\n",
       "      <td>https://s3-us-west-2.amazonaws.com/usgs-lidar-...</td>\n",
       "      <td>POLYGON ((-111.67633 35.3201, -111.67139 35.32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>USGS_LPC_AZ_VerdeKaibab_B2_2018_LAS_2019</td>\n",
       "      <td>1253</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.324541</td>\n",
       "      <td>35728383864</td>\n",
       "      <td>671013.439139</td>\n",
       "      <td>https://s3-us-west-2.amazonaws.com/usgs-lidar-...</td>\n",
       "      <td>POLYGON ((-111.67633 35.3201, -111.67139 35.32...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "# Here we select the URL for the dataset in the first row. \n",
    "# Alternatively, we could use a loop and download all of the available datasets.\n",
    "url = finder.select_url(0)\n",
    "url"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-17T19:32:53.788990Z",
     "start_time": "2025-07-17T19:32:53.773992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3-us-west-2.amazonaws.com/usgs-lidar-public/AZ_Coconino_B1_2019/ept.json'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define tile set\n",
    "To improve computational efficiency and scalability, we can divide our area of interest into a set of tiles using a Tiler object. We specify the total extent of the tileset and the size of each tile. Notice, our extents are defined by geographic coordinates (degrees lat/lon) but we defined the tile size in meters, therefore, we set `convert_units=True`. `get_tiles()` gives us some options to format the tiles. We select the first tile from the upper left corner as a test."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tiler = pdal_piper.Tiler(extents = bbox, tile_size=100, buffer=0, convert_units=True, crs='EPSG:4326')\n",
    "tile_bounds = tiler.get_tiles(format_as_pdal_str=True,flatten=False)\n",
    "print(type(tile_bounds))\n",
    "print(tile_bounds.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-17T19:32:53.867516Z",
     "start_time": "2025-07-17T19:32:53.853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(4, 4)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T19:32:53.962579Z",
     "start_time": "2025-07-17T19:32:53.949520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first_tile_bounds = tile_bounds[0,0]\n",
    "first_tile_bounds"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'([-111.676326, -111.67522509346652], [35.3191979991, 35.320098], [-9999, 9999])/EPSG:4326'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define processing pipeline\n",
    "We need to create a processing pipeline that defines all actions we want PDAL to execute. Each action in the pipeline is described by a 'stage'. In other workflows, the stages are combined in a json-like object, stored as a text file, and run through PDAL via the command line interface. In contrast, `pdal_piper` makes the experience more Pythonic by providing a Python class with built-in documentation for each stage. We use these classes to define each stage, then combine the stages in a list, then pass the list into a Piper object. The Piper object will format the json text and pass it to PDAL for execution."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T19:32:54.025582Z",
     "start_time": "2025-07-17T19:32:53.995582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pdal\n",
    "import numpy as np\n",
    "\n",
    "# Define processing pipeline for the first tile\n",
    "pipelines = []\n",
    "\n",
    "for xi, yi in np.ndindex(tile_bounds.shape):\n",
    "    stages = [\n",
    "        pdal.Reader.ept(filename=url, bounds=tile_bounds[xi, yi]),\n",
    "        pdal.Filter.outlier(method='statistical',mean_k=12,multiplier=2.2),\n",
    "        pdal.Filter.range(limits='Classification[0:6]'),\n",
    "        pdal.Filter.hag_delaunay(),\n",
    "        pdal.Writer.copc(filename=f'test_data/points_{xi}_{yi}.laz', extra_dims='all'),\n",
    "        pdal.Writer.gdal(filename='test_data/canopy_metrics.tif', resolution=1,\n",
    "                         dimension='HeightAboveGround', output_type='all', binmode=True)\n",
    "    ]\n",
    "    pipelines.append(pdal.Pipeline(stages))\n",
    "\n",
    "# View pipeline for first tile in json formatting\n",
    "pipelines[0].toJSON()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"type\": \"readers.ept\", \"bounds\": \"([-111.676326, -111.67522509346652], [35.3191979991, 35.320098], [-9999, 9999])/EPSG:4326\", \"filename\": \"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/AZ_Coconino_B1_2019/ept.json\", \"tag\": \"readers_ept1\"}, {\"type\": \"filters.outlier\", \"method\": \"statistical\", \"mean_k\": 12, \"multiplier\": 2.2, \"tag\": \"filters_outlier1\"}, {\"type\": \"filters.range\", \"limits\": \"Classification[0:6]\", \"tag\": \"filters_range1\"}, {\"type\": \"filters.hag_delaunay\", \"tag\": \"filters_hag_delaunay1\"}, {\"type\": \"writers.copc\", \"extra_dims\": \"all\", \"filename\": \"test_data/points_0_0.laz\", \"tag\": \"writers_copc1\"}, {\"type\": \"writers.gdal\", \"resolution\": 1, \"dimension\": \"HeightAboveGround\", \"output_type\": \"all\", \"binmode\": true, \"filename\": \"test_data/canopy_metrics.tif\", \"tag\": \"writers_gdal1\"}]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T19:33:00.494477Z",
     "start_time": "2025-07-17T19:32:54.058587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Execute pipeline for first tile as a test\n",
    "pipelines[0].execute()\n",
    "pipelines[0].log\n",
    "# If the log is empty, that is good. Otherwise, errors will show up in the log."
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Lastly, we can run the pipeline on all files in the tile set. Tile bounds in the reader stage will automatically be assigned from the unique tile bounds. File names in the writer stages will automatically be assigned a unique value by inserting tile indices between the file basename and the file extension. Pipelines are executed in parallel processes.\n",
    "\n",
    "Note, if `Tiler.buffer>0` and the `filters_crop` stage is used in the pipeline, the filter will automatically use the buffered tile extents in the reader and the unbuffered tile extents in the crop filter. In this special case, the CRS of the Tiler must match the CRS of the point cloud."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T19:33:28.336138Z",
     "start_time": "2025-07-17T19:33:00.525479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Execute pipeline for all tiles\n",
    "logs = pdal_piper.execute_pipelines_parallel(pipelines)\n",
    "[log for log in logs if log != '']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "From here, additional analysis can be carried out with your software of choice."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
